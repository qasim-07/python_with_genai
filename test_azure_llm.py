#!/usr/bin/env python3
"""
Test script for Azure OpenAI LLM Client integration.
"""

# Load environment variables
try:
    from dotenv import load_dotenv
    load_dotenv()
except ImportError:
    print("âš ï¸  python-dotenv not installed. Install with: pip install python-dotenv")

import os
import logging
from llm_client import LLMClient

# Setup logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def test_azure_llm():
    """Test the Azure OpenAI LLM client."""
    print("ğŸ¤– Testing Azure OpenAI LLM Client")
    print("=" * 50)
    
    try:
        # Initialize the Azure OpenAI client
        print("ğŸ”§ Initializing Azure OpenAI client...")
        llm_client = LLMClient()
        print("âœ… Azure OpenAI client initialized successfully!")
        
        # Test connection
        print("\nğŸ” Testing connection...")
        if llm_client.test_connection():
            print("âœ… Connection test successful!")
        else:
            print("âŒ Connection test failed!")
            return
        
        # Test queries
        test_queries = [
            "What is Python programming?",
            "Explain machine learning in simple terms",
            "Write a simple Python function to calculate factorial"
        ]
        
        print(f"\nğŸ§ª Testing {len(test_queries)} queries...")
        print("-" * 50)
        
        for i, query in enumerate(test_queries, 1):
            print(f"\nğŸ“ Query {i}: {query}")
            print("-" * 30)
            
            result = llm_client.query(query, max_tokens=200, temperature=0.7)
            
            if result.get('error'):
                print(f"âŒ Error: {result['error']}")
            else:
                print(f"âœ… Answer: {result['answer'][:150]}...")
                print(f"ğŸ“Š Tokens used: {result.get('tokens_used', 'N/A')}")
                print(f"ğŸ¤– Model: {result.get('model', 'N/A')}")
        
        # Show usage stats
        print(f"\nğŸ“Š Usage Statistics:")
        stats = llm_client.get_usage_stats()
        print(f"  â€¢ Total tokens used: {stats['total_tokens_used']}")
        print(f"  â€¢ Model: {stats['model']}")
        print(f"  â€¢ Estimated cost: ${stats['estimated_cost_usd']:.4f}")
        
        print(f"\nğŸ‰ Azure OpenAI integration test completed successfully!")
        
    except Exception as e:
        logger.error(f"Test failed: {str(e)}")
        print(f"âŒ Test failed: {str(e)}")

if __name__ == "__main__":
    test_azure_llm()
